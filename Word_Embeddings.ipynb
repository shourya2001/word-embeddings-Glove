{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Word Embeddings"
      ],
      "metadata": {
        "id": "snPTf5W90sdC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement cosine similarities from scratch and solve some word analogy problems with pre-trained word vectors."
      ],
      "metadata": {
        "id": "qujKDYlzgG8V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A. Load Pre-trained GloVe Word Vectors with Gensim"
      ],
      "metadata": {
        "id": "Y-RqYJcv05rP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoQgPZiL0yG1",
        "outputId": "6fe7aa30-475f-4f73-de33-a099fcb03847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "k1-WXnpN03RC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_vectors = gensim.downloader.load('glove-wiki-gigaword-50')"
      ],
      "metadata": {
        "id": "WKEQ0svQ0_bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('data type:', type(glove_vectors.vectors))\n",
        "print('# words:', glove_vectors.vectors.shape[0])\n",
        "print('Embedding dimension:', glove_vectors.vectors.shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Emb5Z-y61Bb5",
        "outputId": "2f11eca3-371a-4d3c-934f-a8f305dc9365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data type: <class 'numpy.ndarray'>\n",
            "# words: 400000\n",
            "Embedding dimension: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B. Given a query word, find the top 10 words in the vocabulary that have the highest cosine similarity scores"
      ],
      "metadata": {
        "id": "ZduEu4W61Lvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glove_vectors.most_similar('cat', topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4E-tYXy1Jly",
        "outputId": "053b757e-2023-4c33-e561-3082a0790db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('dog', 0.9218006134033203),\n",
              " ('rabbit', 0.8487821221351624),\n",
              " ('monkey', 0.8041081428527832),\n",
              " ('rat', 0.7891963124275208),\n",
              " ('cats', 0.7865270972251892),\n",
              " ('snake', 0.7798910737037659),\n",
              " ('dogs', 0.7795814871788025),\n",
              " ('pet', 0.7792249917984009),\n",
              " ('mouse', 0.773166835308075),\n",
              " ('bite', 0.7728800177574158)]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement `my_most_similar()` that will do the same thing as the built-in `most_similar()` function above\n"
      ],
      "metadata": {
        "id": "b2CvdJZ41RcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glove_vectors.get_index('apple') # get the index of a word in the vocabulary"
      ],
      "metadata": {
        "id": "IsWUyrr-nb4l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fddab29-e3c3-473d-c310-9101a5255597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3292"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_vectors.index_to_key[3292] # index to word"
      ],
      "metadata": {
        "id": "Jg5oUogSneB7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f0afa1d3-77a3-4ee0-bfc8-1b217fc07712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'apple'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word = 'apple'\n",
        "glove_vectors.get_vector(word) # get the word vector of a word"
      ],
      "metadata": {
        "id": "_vkbFKQ2nfuN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f56718f6-fa4d-4b8d-e8bd-369f1f4c01ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.52042 , -0.8314  ,  0.49961 ,  1.2893  ,  0.1151  ,  0.057521,\n",
              "       -1.3753  , -0.97313 ,  0.18346 ,  0.47672 , -0.15112 ,  0.35532 ,\n",
              "        0.25912 , -0.77857 ,  0.52181 ,  0.47695 , -1.4251  ,  0.858   ,\n",
              "        0.59821 , -1.0903  ,  0.33574 , -0.60891 ,  0.41742 ,  0.21569 ,\n",
              "       -0.07417 , -0.5822  , -0.4502  ,  0.17253 ,  0.16448 , -0.38413 ,\n",
              "        2.3283  , -0.66682 , -0.58181 ,  0.74389 ,  0.095015, -0.47865 ,\n",
              "       -0.84591 ,  0.38704 ,  0.23693 , -1.5523  ,  0.64802 , -0.16521 ,\n",
              "       -1.4719  , -0.16224 ,  0.79857 ,  0.97391 ,  0.40027 , -0.21912 ,\n",
              "       -0.30938 ,  0.26581 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_most_similar(glove_vectors, query_word, topn):\n",
        "    \"\"\"\n",
        "    Find the most similar words to a given query word based on cosine similarity in the GloVe embedding space.\n",
        "\n",
        "    Args:\n",
        "        glove_vectors (Gensim KeyedVectors)\n",
        "        query_word (str): The word for which to find the most similar words.\n",
        "        topn (int): The number of most similar words to return.\n",
        "\n",
        "    Returns:\n",
        "        list of tuples:\n",
        "            - Each tuple contains a word (str) and its corresponding cosine similarity score (float) to the query word.\n",
        "            - The list is sorted in descending order of cosine similarity.\n",
        "    \"\"\"\n",
        "    W = glove_vectors.vectors\n",
        "\n",
        "    if query_word not in glove_vectors:\n",
        "        raise ValueError(f\"'{query_word}' not in vocabulary.\")\n",
        "\n",
        "    query_vec = glove_vectors[query_word]\n",
        "\n",
        "    similarities = []\n",
        "\n",
        "    for word in glove_vectors.index_to_key:\n",
        "        if word == query_word:\n",
        "            continue\n",
        "        word_vec = glove_vectors[word]\n",
        "        cosine_sim = np.dot(query_vec, word_vec) / (np.linalg.norm(query_vec) * np.linalg.norm(word_vec))\n",
        "        similarities.append((word, cosine_sim))\n",
        "\n",
        "    similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    my_list = similarities[:topn]\n",
        "\n",
        "    assert len(my_list) == topn\n",
        "    return my_list"
      ],
      "metadata": {
        "id": "z9VKWxnV1PRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C. What are the highest and lowest vector norms among all the word vectors? Answer with two values."
      ],
      "metadata": {
        "id": "9yQZwJ0b1gye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Your code here\n",
        "def find_max_min_vector_norm(glove_vectors):\n",
        "    \"\"\"\n",
        "    Find the maximum and minimum vector norms among all word vectors in the GloVe embeddings.\n",
        "\n",
        "    Args:\n",
        "        glove_vectors (Gensim KeyedVectors)\n",
        "\n",
        "    Returns:\n",
        "        max_vector_norm (float): The highest vector norm.\n",
        "        min_vector_norm (float): The lowest vector norm.\n",
        "    \"\"\"\n",
        "    max_vector_norm = -np.inf\n",
        "    min_vector_norm = np.inf\n",
        "\n",
        "    for word in glove_vectors.index_to_key:\n",
        "        vector = glove_vectors[word]\n",
        "        norm = np.linalg.norm(vector)\n",
        "\n",
        "        max_vector_norm = max(max_vector_norm, norm)\n",
        "        min_vector_norm = min(min_vector_norm, norm)\n",
        "\n",
        "    return max_vector_norm, min_vector_norm\n",
        "\n",
        "max_vector_norm, min_vector_norm = find_max_min_vector_norm(glove_vectors)\n",
        "print(f'max_vector_norm: {max_vector_norm:.3f}, min_vector_norm: {min_vector_norm:.3f}')"
      ],
      "metadata": {
        "id": "IzIc2brD2VdI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef061ffa-edf3-4230-9131-0300778cfad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_vector_norm: 14.122, min_vector_norm: 0.047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## D. Why is cosine similarity better than dot product when calculating similarities between word vectors?"
      ],
      "metadata": {
        "id": "PyOJW6dg1rkG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cosine similarity is better than dot product because it only considers the direction of the vector and not the magnitude unlike dot product which factors in magnitude as well as direction. Considering only the direction is better as the magnitude depends on the frequency and the context which may skew the dot product results."
      ],
      "metadata": {
        "id": "zZU2E2fC2p-0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Your implementation of `my_most_similar()` should pass the test cases below"
      ],
      "metadata": {
        "id": "PErzUd1816x7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def diff_results(oracle_list, my_list):\n",
        "  for oracle, mine in zip(oracle_list, my_list):\n",
        "    assert oracle[0] == mine[0], \"find the wrong word\"\n",
        "    assert np.isclose(oracle[1], mine[1]), \"wrong consine similarity\"\n",
        "\n",
        "for query in ['computer', 'frog', 'car']:\n",
        "  oracle_list = glove_vectors.most_similar(query, topn=10)\n",
        "  my_list = my_most_similar(glove_vectors, query, topn=10)\n",
        "  diff_results(oracle_list, my_list)"
      ],
      "metadata": {
        "id": "r4Yi1lWK1c4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## E. We visualize the word embeddings with PCA below. What do you see in the figure?\n",
        "- Hint: Each dot corresponds to a word vector. Do you observe any meaningful direction between related words?\n",
        "- You do not need to write any code in this question"
      ],
      "metadata": {
        "id": "dD41_iZH2EYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "Z = pca.fit_transform(glove_vectors.vectors)"
      ],
      "metadata": {
        "id": "kSAPfG3L19kM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,5))\n",
        "for word in ['king', 'queen', 'lord', 'lady', 'prince', 'princess', 'men', 'women']:\n",
        "  point = Z[glove_vectors.get_index(word)]\n",
        "  plt.scatter(point[0], point[1], color='b')\n",
        "  plt.annotate(word, (point[0], point[1]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "0Jxt-2hc2H8r",
        "outputId": "976d7a09-f1e6-4712-975b-c2a79780337b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: Similar words point in similar directions."
      ],
      "metadata": {
        "id": "gUyMqZ9v51HY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## F. Word Analogy: prince is to princess as lord is to?\n",
        "  - word1: `prince`, word2: `princess`, word3: `lord`\n",
        "  - `direction = vec(word2) - vec(word1)`\n",
        "  - `vec_tgt = vec(word3) + direction`\n",
        "  - Calcuate the cosine similarities between `vec_tgt` and all the words in the vocabulary, **except for word3**.\n",
        "  - Return the word that has the highest cosine similarity score."
      ],
      "metadata": {
        "id": "t9crJ6Dx3MCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_analogy(glove_vectors, word1, word2, word3):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        glove_vectors (Gensim KeyedVectors)\n",
        "        word1 (str): The first word in the analogy.\n",
        "        word2 (str): The second word in the analogy.\n",
        "        word3 (str): The third word in the analogy for which to find the analogous word.\n",
        "\n",
        "    Returns:\n",
        "        pred_word (str): The word that best completes the analogy.\n",
        "    \"\"\"\n",
        "\n",
        "    # Your code here\n",
        "    if word1 not in glove_vectors or word2 not in glove_vectors or word3 not in glove_vectors:\n",
        "        raise ValueError(f\"One of the words: {word1}, {word2}, {word3} is not in the vocabulary.\")\n",
        "\n",
        "    vec1 = glove_vectors[word1]\n",
        "    vec2 = glove_vectors[word2]\n",
        "    vec3 = glove_vectors[word3]\n",
        "\n",
        "    direction = vec2 - vec1\n",
        "    vec_tgt = vec3 + direction\n",
        "\n",
        "    max_sim = -np.inf\n",
        "    pred_word = None\n",
        "\n",
        "    for word in glove_vectors.index_to_key:\n",
        "        if word == word3:\n",
        "            continue\n",
        "\n",
        "        word_vec = glove_vectors[word]\n",
        "\n",
        "        cosine_sim = np.dot(vec_tgt, word_vec) / (np.linalg.norm(vec_tgt) * np.linalg.norm(word_vec))\n",
        "\n",
        "        if cosine_sim > max_sim:\n",
        "            max_sim = cosine_sim\n",
        "            pred_word = word\n",
        "\n",
        "    print(f'{word1} is to {word2} as {word3} is to? {pred_word}')\n",
        "    assert pred_word != word3\n",
        "    return pred_word"
      ],
      "metadata": {
        "id": "i51kuBJr3UW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_word = word_analogy(glove_vectors, 'prince', 'princess', 'lord')\n",
        "pred_word = word_analogy(glove_vectors, 'aunt', 'uncle', 'queen')\n",
        "pred_word = word_analogy(glove_vectors, 'london', 'england', 'paris')\n",
        "pred_word = word_analogy(glove_vectors, 'cat', 'cats', 'car')"
      ],
      "metadata": {
        "id": "y1e-zPgb9Gul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68548387-fcbd-4c2e-95da-f121ffda7439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prince is to princess as lord is to? lady\n",
            "aunt is to uncle as queen is to? king\n",
            "london is to england as paris is to? france\n",
            "cat is to cats as car is to? cars\n"
          ]
        }
      ]
    }
  ]
}